'''
Run TraCeR on all cells within a flow cell
find . -maxdepth 1 -type f -size -2M -name "*_001.fastq.gz" -exec ls -lh {} \;
^ Find all fastq.gz files that are less than 2Mb
find . -maxdepth 1 -type f -size -2M -name "*_001.fastq.gz" -exec mv {} small_fastqs/ \;
^ Here I moved all the small fastq.gz files to a folder named "small_fastqs"
I also MOVED the undetermined file (if generated by bcl2fastq)
'''
import re
import pandas as pd
from ruffus import *
from cgatcore import pipeline as P
import sys
import glob
import os
import pydot
import pygraphviz

params = P.get_parameters("pipeline_tracer.yml")  # define params here

# @transform("*.fastq.gz", regex(r'(.*).fastq.gz'), r'fastqc_results/\1_fastqc.html')
# def fastqc(infile, outfile):
#     ''' run fastqc on all files'''
#
#     statement = '''fastqc --nogroup -o fastqc %(infile)s'''
#
#     P.run(statement, job_queue=PARAMS["q"], job_threads=1, job_memory='2G', job_condaenv='tracer')
#
# @follows(mkdir("multiqc_results"))
# @merge(fastqc, "multiqc_results/fastqc_report.html")
# def multiqc(infiles, outfile):
#     ''' run multiqc to collect fastq stats '''
#
#     statement = """export LC_ALL=en_US.UTF-8 &&
#                    export LANG=en_US.UTF-8 &&
#                    multiqc fastqc/ -f -n %(outfile)s"""
#     P.run(statement, job_queue=PARAMS["q"])

@transform("*.fastq.gz", regex(r'(.*)_R1_001.fastq.gz'), r'20201120_full_run/\1_B2/filtered_TCR_seqs/filtered_TCRs.txt') #regex function from ruffus
def tracer_assemble(infile, outfile):

# /filtered_TCR_seqs/filtered_TCRs.txt
    '''run tracer assemble on fastq fastq.gz files
    Multiple outputs:
    For each cell, an /<output_directory>/<cell_name> directory will be created.
    This will contain 6 subdirectories:
    1) aligned_reads - Bowtie2 output
    2) Trinity_output - fasta files for each locus where contigs assembled
    3) IgBLAST_output -
    4) unfiltered_TCR_seqs - TCR sequences that were assembled prior to filtering
    5) expression_quantification - Kallisto/Salmon expression quantification
    6) filtered_TCR_seqs - recombinants filtered so 2 most expressed from each locus retained
    '''
    cellname = infile.replace("_R1_001.fastq.gz","_B2")
    # I'VE CHANGED THIS SINCE I RAN IT ON TWO CELLS ^
    print(cellname)
    statement = '''
                tracer assemble
                --ncores %(assemble_ncores)s
                --config_file %(tracer_options_config.file)s
                --loci %(tracer_options_loci)s
                --resource_dir %(tracer_options_resource.dir)s
                --species %(tracer_options_species)s
                --quant_method %(assemble_quant.method)s

                %(assemble_single.end)s
                --fragment_length %(assemble_fragment.length)s
                --fragment_sd %(assemble_fragment.sd)s
                %(assemble_small.index)s

                %(infile)s
                %(cellname)s
                %(assemble_output.directory)s

                > %(cellname)s_standardout.log
                2> %(cellname)s_standarderror.log'''

    P.run(statement,job_queue=params["q"],
    job_condaenv='tracer', job_threads=params["assemble_ncores"],
    job_memory=params["assemble_job.memory"])

@merge(tracer_assemble, "20201120_full_run/filtered_TCR_summary/TCR_summary.txt")
def tracer_summarise(infile, outfiles):

    infile_directory = infile[0]
    infile_directory_list = infile_directory.split(os.sep)
    statement_infile_directory = infile_directory_list[0]
    print(statement_infile_directory)

    '''run tracer summarise on output of tracer_assemble
    Multiple outputs to <input_dir>/filtered_TCR_summary
    1) TCR_summary.txt
    2) recombinants.txt
    3) reconstructed_lengths_TCR[A|B]
    4) clonotype_sizes
    5) and 6) only enabled in Graphviz installed
    (see https://github.com/Teichlab/tracer)
    '''
    statement = '''
    tracer summarise
    --config_file %(tracer_options_config.file)s
    --loci %(tracer_options_loci)s
    --resource_dir %(tracer_options_resource.dir)s
    --species %(tracer_options_species)s
    %(summarise_keep.invariant)s
    %(summarise_no.networks)s
    %(statement_infile_directory)s
    '''
    P.run(statement, job_queue='all.q',
         job_threads=4,
         job_memory='2G',
         job_condaenv='tracer')
if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
